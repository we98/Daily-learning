## 分布式
#### 1、分布式锁

- 在单进程多线程的条件下，当很多线程访问统一接口时，而该接口如果操作了共享对象，则需要使用Java的内置锁进行同步，可以保证线程安全。但是如果在多进程条件下，该锁只是在进程内部的，也就是每一个进程都有一把这样的锁，这样是无法保证线程安全的。因此，需要一种第三方媒介来作为任何一个机器上任何一个进程都能看到的一把锁，这样便可以保证线程安全。![1565405544531](pictures\为什么要有分布式锁.png)

- 因此，在设计这个第三方媒介作为分布式锁时，要注意以下几个问题：
  - 这个锁是公平锁还是非公平锁
  - 排他锁还是共享锁
  - 是否可重入
  - 阻塞还是非阻塞锁（当一个线程抢不到这把锁时，该线程的状态）
- 因此，根据这几个设计思想，为了实现排他性，可以选用以下几种方式来实现分布式锁：![1565408480561](pictures\分布式锁的可选技术.png)
  - 文件系统，同一目录下不可能有两个的文件名，可以实现排他性
  - 数据库
  - redis
  - Zookeeper
- 以下是这几个不同技术选型的优缺点![1565408683118](pictures\不同分布式锁实现的优缺点.png)
  - 对于数据库和文件系统而言，都没有失效时间，因此容易导致死锁和单点故障问题，性能较差
    - 使用文件系统实现分布式锁的方法：比如有这样的约定，在目录/下创建lock.txt文件成功即为获取成功对应的锁，获取成功后，便可以去执行共享代码块。对于没有获取成功的线程而言，**该线程不能直接简单的阻塞**，因为阻塞了之后，在多个分布式进程之间是没有所谓的通知唤醒的，因此没有获取成功的线程应该做类似轮询的工作，一直检测该文件是否存在。但是，**如果当获得锁的线程意外终止，并没有及时地释放这把锁，则会导致死锁问题。**
    - 如何解决这种死锁问题？一种方法是，在存储这把锁的机器内开启一个守护线程，当发现超时机制时，将该文件删除。那么仍然存在问题，如果获取锁的线程只是花了很长时间来做业务，并没有意外终止而超时，如何解决？目前的解决方案就是评估业务所需要的时间，根据不同的业务给予不同的超时时间
    - 数据库实现的方式与文件系统类似，只不过约定有所改变而已，如文件系统是临时创建文件代表抢锁。数据库的实现方式则是在一个唯一性的表中插入数据代表抢锁
  - redis可能出现短时间死锁的可能
    - 对redis而言，本身就可以做到超时检测，不需要手动部署守护线程。因此，使用redis时，要像上文提到的那样，根据不同的业务的锁设置不同的超时时间
  - Zookeeper，也用来解决分布式锁的问题，在上文提到的死锁问题，以及没有得到锁的线程需要轮询这种不优雅的方式都得到了解决。Zookeeper的特性之一是可以创建临时节点，当与之相连的客户端断开连接的时候，该临时节点就会被自动地清除。实质上，这是Zookeeper的心跳检测机制，client通过心跳机制与服务端保持一个长连接，一旦client断开，服务端就会将这个client创建的临时节点给删除。通过这样的机制，不需要为每个业务设置超时时间，也不会出现死锁问题。

#### 2、分布式事务

有两种分布式事务

跨系统的分布式事务

![1565582245031](pictures\分布式事务——微服务.png)

跨库的分布式事务

![1565582312747](pictures\分布式事务——跨库事务.png)



XA/JTA规范对于微服务架构下的分布式事务不能解决，但是可以非常好的解决平常的拆库场景

![1565583291603](pictures\两阶段提交协议.png)

TCC和XA都是两阶段提交的解决方案

两阶段提交的思想是，引入一个协调者，第一阶段进行prepare，每个数据库执行sql语句，但是并不提交，并将sql语句的执行结果报告给协调者，第二阶段协调者根据各个数据库报告给自己的情况，通知每一个数据库commit或者rollback，第一个阶段相当于把所有的资源都锁住，然后第二阶段commit或rollback成功的几率非常高，所以两阶段提交协议可以有效的提高跨库事务成功的可能性。但是没有一种技术可以100%保证跨库事务成功，比如第二阶段commit了其中一个库，而由于网络或其他原因第二个库挂掉无法操作也会导致数据不一致的情况，但是第一阶段的将所有资源都锁住的操作可以大大降低这种可能性，提高成功的概率，这也就是分两阶段进行跨库事务处理的原因。

如果出现网络问题，第二阶段可以进行不断的重试，如果数据库挂掉，可以通过日志的方式在后期进行人工补偿。

![1565583727787](pictures\两阶段提交.png)

![1565584424857](pictures\atomikos实现了XAJTA规范的两阶段提交协议.png)

atomikos就实现了基于XA/JTA规范的两阶段提交协议，可以很容易的处理跨库问题（JTA，java transaction api，是java基于两阶段提交协议自定义的一系列接口，这个包在javax.transaction下，都是接口，而atomikos这个包则是实现了jta一系列接口的可用类），如下是使用atomikos的方式（UserTransaction是jta中的接口，UserTransactionImp是atomikos中的具体实现），与普通事务的写法十分类似：

![1565584892839](pictures\atomikos使用.png)

具体的，两阶段提交协议表现在userTransaction.commit()方法中，大致思想思路就是先执行所有rm的语句，在第一阶段询问执行结果，在第二阶段进行commit或rollback

![1565585382893](pictures\两阶段提交在atomikos中的大致实现3.png)

![1565585170408](pictures\两阶段提交在atomikos中的大致实现.png)

![1565585284327](pictures\两阶段提交在atomikos中的大致实现2.png)

以上是atomikos实现的核心原理，但是atomikos在实现的时候还会做更细致的事情，比如在第二阶段的两次提交中第二个提交发生失败，则会重试，如果重试也不行，则会记录日志













在分布式的情况下，CAS理论最多只能满足其中的两个

![1565585833367](pictures\CAP理论和JTA.png)



![1565585893911](G:\学习资料\学习笔记\Daily-learning\面试题目\pictures\BASE理论.png)









在微服务系统下（跨jvm，跨系统，跨数据库），如何实现分布式事务？

![1565585987049](pictures\微服务解决方案TCC.png)

针对于JTA而言，在整个分布式事务期间，所有涉及到的资源都会加锁（预提交不是真正的提交，是对当前行的数据加锁（但如果锁没加好会锁表）），当同时操作几十张表时，这样的方案会导致性能非常差，可用性很低。因此，针对这种情况，TCC是其中一种解决方案。这种方式与2PC十分类似，只不过不向2PC那样全程加锁，在第一阶段，预留资源，也就是将访问到的资源修改为一种中间状态（比如在积分服务中增加一列“预积分”，并设置10），然后释放锁。在第二状态，如果第一阶段所有资源预留成功，将会根据第一阶段的中间状态修改所有资源的值（如将积分服务中的真正积分加10，将“预积分”列置0），而如果存在一个不成功，则所有的状态cancel。因此，在微服务架构中，使用TCC进行分布式事务管理时，所有的服务都要提供类似于try confirm和cancel的api。

在第二阶段中，如果某一个commit失败，则解决方法与JAT类似，重试或者记log

![1565586495751](pictures\TCC两个阶段.png)

TCC与XA/JTA对比，二者本质区别在于是否持续对资源进行加锁，当加锁时，这种锁的粒度是非常大的，因此XA/JTA解决方案对于微服务这种对可用性要求较高的场景并不适用。而在TCC中，每次调用一个服务的接口时，其对应资源的sql语句已经commit完毕，因此在整个程序执行期间，不会有大粒度的锁存在。简单的说，TCC相比于JTA来说，没有一把全局的大锁，而是把锁的粒度减小到每个服务提供的接口里面。因此，对于越复杂的场景，锁的粒度减小的越厉害，并发度提高的也就更好。

![1565587520774](pictures\TCC与JTA对比.png)

其实atomikos除了实现了JTA，也有支持TCC，但是那个模块收费

当使用TCC框架时，大致这样做，每个服务模块都要引入TCC框架，这个框架会记下日志，即使发生故障，重启之后便可以根据日志进行恢复

![1565587733688](pictures\使用TCC框架原理图.png)